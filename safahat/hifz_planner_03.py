import streamlit as st
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

tokenizer = AutoTokenizer.from_pretrained("gemini/gemini-2.0-flash")
model = AutoModelForCausalLM.from_pretrained("gemini/gemini-2.0-flash")

def generate_plan(prompt):
    inputs = tokenizer(prompt, return_tensors="pt")
    outputs = model.generate(**inputs, max_length=500)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

def app():
    st.title("ğŸ§ ğŸ“– Ù…ÙØ®Ø·Ø· Ø­ÙØ¸ Ø§Ù„Ù‚Ø±Ø¢Ù†")

    surah_name = st.text_input("Ø§Ø³Ù… Ø§Ù„Ø³ÙˆØ±Ø©", "Ø§Ù„Ø¨Ù‚Ø±Ø©")
    from_ayah = st.number_input("Ù…Ù† Ø§Ù„Ø¢ÙŠØ©", min_value=1, value=1)
    to_ayah = st.number_input("Ø¥Ù„Ù‰ Ø§Ù„Ø¢ÙŠØ©", min_value=from_ayah, value=7)
    total_days = st.number_input("Ø¹Ø¯Ø¯ Ø£ÙŠØ§Ù… Ø§Ù„Ø­ÙØ¸", min_value=1, value=7)
    days_per_week = st.slider("ÙƒÙ… ÙŠÙˆÙ… ØªØ­ÙØ¸ ÙÙŠ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ØŸ", 1, 7, 5)

    if st.button("Ø£Ù†Ø´Ø¦ Ø§Ù„Ø®Ø·Ø© Ø§Ù„Ø°ÙƒÙŠØ© âœ¨"):
        prompt = f"""
        Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙÙŠ ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…. Ù…Ù‡Ù…ØªÙƒ ØªÙ‚Ø³ÙŠÙ… Ø­ÙØ¸ Ø³ÙˆØ±Ø© {surah_name} Ù…Ù† Ø§Ù„Ø¢ÙŠØ© {from_ayah} Ø¥Ù„Ù‰ Ø§Ù„Ø¢ÙŠØ© {to_ayah}
        Ø¹Ù„Ù‰ {total_days} ÙŠÙˆÙ…ØŒ Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø©:
        - ØªÙ‚Ø³Ù… Ø§Ù„Ø¢ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø£Ùˆ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨.
        - ÙŠÙƒÙˆÙ† Ø§Ù„Ø­Ù…Ù„ Ø§Ù„ÙŠÙˆÙ…ÙŠ Ù…ØªÙˆØ§Ø²Ù†.
        - ØªØ¸Ù‡Ø± Ø§Ù„Ø®Ø·Ø© Ø¨Ø´ÙƒÙ„ Ø¬Ø¯ÙˆÙ„: Ø§Ù„ÙŠÙˆÙ… - Ø§Ù„Ø¢ÙŠØ§Øª - Ù…Ù„Ø§Ø­Ø¸Ø§Øª.

        Ø£Ø®Ø±Ø¬ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙƒØ¬Ø¯ÙˆÙ„ Ù…Ù†Ø¸Ù… ÙˆØ§Ø¶Ø­ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
        """

        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø®Ø·Ø© Ø§Ù„Ø°ÙƒÙŠØ©..."):
            try:
                plan_text = generate_plan(prompt)
                st.markdown("### âœ¨ Ø®Ø·Ø© Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ø°ÙƒÙŠ:")
                st.markdown(plan_text)
            except Exception as e:
                st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")
