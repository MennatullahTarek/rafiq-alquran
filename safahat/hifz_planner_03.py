import streamlit as st
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

def app():
    st.title("๐ง๐ ููุฎุทุท ุญูุธ ุงููุฑุขู")
    st.markdown("ุฎุทุท ุญูุธู ุจูุงุกู ุนูู ูุฏุฑุงุชู ูุนุฏุฏ ุงูุฃูุงูุ ูุณูููู ุฑููู ุงููุฑุขู ุจุชูุณูู ุงูุญูุธ ูู ุจุทุฑููุฉ ุฐููุฉ ๐ก.")
    
    surah_name = st.text_input("ุงุณู ุงูุณูุฑุฉ", "ุงูุจูุฑุฉ")
    from_ayah = st.number_input("ูู ุงูุขูุฉ", min_value=1, value=1)
    to_ayah = st.number_input("ุฅูู ุงูุขูุฉ", min_value=from_ayah, value=7)
    total_days = st.number_input("ุนุฏุฏ ุฃูุงู ุงูุญูุธ", min_value=1, value=7)
    days_per_week = st.slider("ูู ููู ุชุญูุธ ูู ุงูุฃุณุจูุนุ", 1, 7, 5)
    
    @st.cache_resource(show_spinner=False)
    def load_model():
        model_name = "aubmindlab/aragpt2-base"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForCausalLM.from_pretrained(model_name)
        return tokenizer, model
    
    tokenizer, model = load_model()
    
    def generate_plan(prompt):
        inputs = tokenizer.encode(prompt, return_tensors="pt")
        outputs = model.generate(
            inputs,
            max_length=300,
            num_return_sequences=1,
            do_sample=True,
            top_p=0.9,
            temperature=0.7,
            pad_token_id=tokenizer.eos_token_id,
        )
        return tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    def parse_to_table(plan_text):
        data = []
        for line in plan_text.split("\n"):
            if "ุงูููู" in line and "-" in line:
                parts = line.split("-")
                if len(parts) >= 2:
                    day = parts[0].strip()
                    verses = parts[1].strip()
                    note = parts[2].strip() if len(parts) > 2 else ""
                    data.append({"ุงูููู": day, "ุงูุขูุงุช": verses, "ููุงุญุธุงุช": note})
        return data
    
    if st.button("ุฃูุดุฆ ุงูุฎุทุฉ ุงูุฐููุฉ โจ"):
        with st.spinner("ุฌุงุฑู ุชูููุฏ ุงูุฎุทุฉ..."):
            try:
                prompt = f"""
                ุฃูุช ูุณุงุนุฏ ุฐูู ูู ุชุนููู ุงููุฑุขู ุงููุฑูู. ูููุชู ุชูุณูู ุญูุธ ุณูุฑุฉ {surah_name} ูู ุงูุขูุฉ {from_ayah} ุฅูู ุงูุขูุฉ {to_ayah}
                ุนูู {total_days} ูููุ ูุน ูุฑุงุนุงุฉ:
                - ุชูุณู ุงูุขูุงุช ุญุณุจ ุงููุนูู ุฃู ุงูุทูู ุงูููุงุณุจ.
                - ูููู ุงูุญูู ุงููููู ูุชูุงุฒู.
                - ุชุธูุฑ ุงูุฎุทุฉ ุจุดูู ุฌุฏูู: ุงูููู - ุงูุขูุงุช - ููุงุญุธุงุช.
                ุฃุฎุฑุฌ ุงููุชูุฌุฉ ูุฌุฏูู ููุธู ูุงุถุญ ุจุงููุบุฉ ุงูุนุฑุจูุฉ.
                """
                plan_text = generate_plan(prompt)
                st.markdown("### โจ ุฎุทุฉ ุงูุญูุธ ุงูุฐูู:")
                st.text(plan_text)
    
                table_data = parse_to_table(plan_text)
                if table_data:
                    st.table(table_data)
                else:
                    st.info("ูู ุฃุชููู ูู ุชุญููู ุงูุฎุทุฉ ุฅูู ุฌุฏูู. ุฑุจูุง ุชุญุชุงุฌ ุชุนุฏูู ุงูุชูุณูู ููููุงู.")
    
            except Exception as e:
                st.error(f"ุญุฏุซ ุฎุทุฃ: {str(e)}")



if __name__ == "__main__":
    app()
