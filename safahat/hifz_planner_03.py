import streamlit as st
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
import pandas as pd
from fpdf import FPDF
from io import BytesIO
import re

def app():
    st.title("Ù…ÙØ®Ø·Ø· Ø­ÙØ¸ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø¹Ù„Ù‰ Streamlit Cloud")

    model_name = "aubmindlab/aragpt2-base"

    @st.cache_resource(show_spinner=False)
    def load_model():
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForCausalLM.from_pretrained(model_name)
        return tokenizer, model

    tokenizer, model = load_model()

    surah_name = st.text_input("Ø§Ø³Ù… Ø§Ù„Ø³ÙˆØ±Ø©", "Ø§Ù„Ø¨Ù‚Ø±Ø©")
    from_ayah = st.number_input("Ù…Ù† Ø§Ù„Ø¢ÙŠØ©", min_value=1, value=1)
    to_ayah = st.number_input("Ø¥Ù„Ù‰ Ø§Ù„Ø¢ÙŠØ©", min_value=from_ayah, value=7)
    total_days = st.number_input("Ø¹Ø¯Ø¯ Ø£ÙŠØ§Ù… Ø§Ù„Ø­ÙØ¸", min_value=1, value=7)

    if st.button("Ø£Ù†Ø´Ø¦ Ø§Ù„Ø®Ø·Ø©"):
        prompt = f"Ù‚Ø³Ù… Ø³ÙˆØ±Ø© {surah_name} Ù…Ù† Ø§Ù„Ø¢ÙŠØ© {from_ayah} Ø¥Ù„Ù‰ Ø§Ù„Ø¢ÙŠØ© {to_ayah} Ø¹Ù„Ù‰ {total_days} ÙŠÙˆÙ…ØŒ Ù…Ø¹ Ø®Ø·Ø© Ø­ÙØ¸ ÙŠÙˆÙ…ÙŠØ© ÙˆØ§Ø¶Ø­Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´ÙƒÙ„ Ø¬Ø¯ÙˆÙ„: Ø§Ù„ÙŠÙˆÙ… - Ø§Ù„Ø¢ÙŠØ§Øª - Ù…Ù„Ø§Ø­Ø¸Ø§Øª."
        inputs = tokenizer.encode(prompt, return_tensors="pt")
        outputs = model.generate(
            inputs,
            max_length=300,
            num_return_sequences=1,
            no_repeat_ngram_size=2,
            do_sample=True,
            temperature=0.7,
        )
        result = tokenizer.decode(outputs[0], skip_special_tokens=True)


        rows = []
        for line in result.split('\n'):

            match = re.match(r'Ø§Ù„ÙŠÙˆÙ…\s*(\d+)\s*:\s*Ø¢ÙŠØ§Øª\s*([\d\-ØŒ]+)\s*(.*)', line)
            if match:
                day = match.group(1)
                ayat = match.group(2)
                notes = match.group(3).strip()
                rows.append({"Ø§Ù„ÙŠÙˆÙ…": day, "Ø§Ù„Ø¢ÙŠØ§Øª": ayat, "Ù…Ù„Ø§Ø­Ø¸Ø§Øª": notes})

        if rows:
            df = pd.DataFrame(rows)
            st.markdown("### Ø®Ø·Ø© Ø§Ù„Ø­ÙØ¸ ÙÙŠ Ø¬Ø¯ÙˆÙ„:")
            st.dataframe(df)

            def create_pdf(dataframe):
                pdf = FPDF()
                pdf.add_page()
                pdf.set_font("Arial", size=14)
                pdf.cell(0, 10, f"Ø®Ø·Ø© Ø­ÙØ¸ Ø³ÙˆØ±Ø© {surah_name}", ln=True, align='C')
                pdf.ln(10)
                pdf.set_font("Arial", size=12)

                # Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„
                col_widths = [30, 50, 110]
                headers = ["Ø§Ù„ÙŠÙˆÙ…", "Ø§Ù„Ø¢ÙŠØ§Øª", "Ù…Ù„Ø§Ø­Ø¸Ø§Øª"]
                for i, header in enumerate(headers):
                    pdf.cell(col_widths[i], 10, header, border=1, align='C')
                pdf.ln()

                for _, row in dataframe.iterrows():
                    pdf.cell(col_widths[0], 10, str(row["Ø§Ù„ÙŠÙˆÙ…"]), border=1, align='C')
                    pdf.cell(col_widths[1], 10, str(row["Ø§Ù„Ø¢ÙŠØ§Øª"]), border=1, align='C')
                    pdf.cell(col_widths[2], 10, str(row["Ù…Ù„Ø§Ø­Ø¸Ø§Øª"]), border=1, align='R')
                    pdf.ln()

                pdf_output = BytesIO()
                pdf.output(pdf_output)
                pdf_output.seek(0)
                return pdf_output

            pdf_file = create_pdf(df)
            st.download_button(
                label="ğŸ“„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø®Ø·Ø© ÙƒÙ…Ù„Ù PDF",
                data=pdf_file,
                file_name="Ø®Ø·Ø©_Ø§Ù„Ø­ÙØ¸.pdf",
                mime="application/pdf"
            )
        else:
            st.markdown("### Ø®Ø·Ø© Ø§Ù„Ø­ÙØ¸:")
            st.write(result)
