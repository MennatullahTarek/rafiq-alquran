import streamlit as st
import json
import re
from transformers import pipeline
import nest_asyncio

nest_asyncio.apply()

# ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆØ±
@st.cache_resource
def load_surah_data(filepath="surah_info.json"):
    with open(filepath, "r", encoding="utf-8") as f:
        return json.load(f)

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ø³ÙˆØ±Ø© Ù…Ù† Ø§Ù„Ø³Ø¤Ø§Ù„
def extract_surah_name(question):
    match = re.search(r"Ø³ÙˆØ±Ø©\s+([\w]+)", question)
    return match.group(1) if match else None

# ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø³ÙŠØ§Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
def get_context_from_surah(surah_name, surah_data):
    for surah in surah_data:
        if surah_name == surah["name_ar"]:
            return (
                f"Ø³ÙˆØ±Ø© {surah['name_ar']} Ù‡ÙŠ Ø³ÙˆØ±Ø© {surah['revelation_place']}ØŒ "
                f"Ø¹Ø¯Ø¯ Ø¢ÙŠØ§ØªÙ‡Ø§ {surah['verses_count']}ØŒ "
                f"Ù†Ø²Ù„Øª ÙÙŠ {surah['revelation_time']}ØŒ "
                f"ÙˆØ§Ù„Ù‡Ø¯Ù Ù…Ù†Ù‡Ø§: {surah['reasons']}."
            )
    return ""

# ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ LLM (QA model)
@st.cache_resource
def load_llm_model():
    with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºØ©... ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±"):
        model = pipeline("question-answering", model="Damith/AraELECTRA-discriminator-QuranQA")
    return model

# ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯ Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ø³ÙŠØ§Ù‚
def generate_response_with_llm(question, context, llm):
    if not context:
        return "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„."
    result = llm(question=question, context=context)
    return result["answer"]

# Ø´Ø§Øª Ø¨ÙˆØª
def generate_response(message, surah_data, llm):
    msg = message.strip()

    if "Ø§Ù„Ø³Ù„Ø§Ù…" in msg or "Ù…Ø±Ø­Ø¨Ø§" in msg:
        return "ÙˆØ¹Ù„ÙŠÙƒÙ… Ø§Ù„Ø³Ù„Ø§Ù…! Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙŠØ§ Ø±ÙÙŠÙ‚ØŒ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ ğŸ˜Š"

    if "Ø´ÙƒØ±Ø§" in msg or "Ù…ØªØ´ÙƒØ±" in msg:
        return "Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø­Ø¨ ÙˆØ§Ù„Ø³Ø¹Ø©! ÙŠØ³Ø¹Ø¯Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø£ÙŠ ÙˆÙ‚Øª ğŸŒŸ"

    surah_name = extract_surah_name(msg)
    if surah_name:
        context = get_context_from_surah(surah_name, surah_data)
        if context:
            return generate_response_with_llm(msg, context, llm)
        else:
            return f"Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø³ÙˆØ±Ø© {surah_name}."

    return "Ù„Ù… Ø£ÙÙ‡Ù… Ø³Ø¤Ø§Ù„Ùƒ ØªÙ…Ø§Ù…Ù‹Ø§ ğŸ¤”ØŒ Ø­Ø§ÙˆÙ„ ØªÙƒØªØ¨Ù‡ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£ÙˆØ¶Ø­ Ø£Ùˆ Ø§Ø³Ø£Ù„Ù†ÙŠ Ø¹Ù† Ø³ÙˆØ±Ø© Ù…Ø¹ÙŠÙ†Ø©."

# ØªØµÙ…ÙŠÙ… ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ (HTML + CSS)
def render_message(user_msg, bot_msg):
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… HTML ÙˆCSS Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø¨Ø´ÙƒÙ„ Ø¬Ù…ÙŠÙ„
    message_html = f"""
    <style>
    .chat-container {{
        max-width: 700px;
        margin: 0 auto;
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }}
    .message {{
        display: flex;
        margin-bottom: 12px;
        align-items: flex-start;
    }}
    .user-msg {{
        justify-content: flex-start;
    }}
    .bot-msg {{
        justify-content: flex-end;
    }}
    .bubble {{
        max-width: 70%;
        padding: 12px 18px;
        border-radius: 18px;
        font-size: 16px;
        line-height: 1.4;
        white-space: pre-wrap;
        word-wrap: break-word;
    }}
    .user-bubble {{
        background-color: #DCF8C6;
        color: #000;
        border-bottom-left-radius: 0;
    }}
    .bot-bubble {{
        background-color: #2F80ED;
        color: white;
        border-bottom-right-radius: 0;
    }}
    .user-icon {{
        font-weight: bold;
        margin-right: 10px;
        color: #34B7F1;
        min-width: 30px;
        text-align: center;
    }}
    .bot-icon {{
        font-weight: bold;
        margin-left: 10px;
        color: #E2E2E2;
        min-width: 30px;
        text-align: center;
    }}
    </style>

    <div class="chat-container">
        <div class="message user-msg">
            <div class="user-icon">ğŸ‘¤</div>
            <div class="bubble user-bubble">{user_msg}</div>
        </div>
        <div class="message bot-msg">
            <div class="bubble bot-bubble">{bot_msg}</div>
            <div class="bot-icon">ğŸ¤–</div>
        </div>
    </div>
    """
    st.markdown(message_html, unsafe_allow_html=True)

# ØªØ·Ø¨ÙŠÙ‚ Streamlit
def app():

    st.title("ğŸ¤– Ø±ÙÙŠÙ‚ Ø§Ù„Ù‚Ø±Ø¢Ù† - Ø´Ø§Øª Ø¨ÙˆØª Ù…Ø¹ QA")

    surah_data = load_surah_data()
    qa_pipeline = load_llm_model()

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    if "user_input" not in st.session_state:
        st.session_state.user_input = ""

    # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¨Ø´ÙƒÙ„ ÙÙ‚Ø§Ø¹Ø§Øª
    if st.session_state.chat_history:
        for user_msg, bot_msg in st.session_state.chat_history:
            render_message(user_msg, bot_msg)

    # Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø¹ Ø²Ø± Ø¥Ø±Ø³Ø§Ù„ Ø¨Ø¬Ø§Ù†Ø¨ Ø¨Ø¹Ø¶
    col1, col2 = st.columns([8,1])
    with col1:
        user_input = st.text_input("ğŸ’¬ Ø£ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§:", value=st.session_state.user_input, key="input_box")
    with col2:
        send_button = st.button("â–¶ï¸")

    if send_button and user_input.strip():
        response = generate_response(user_input, surah_data, qa_pipeline)
        st.session_state.chat_history.append((user_input, response))
        st.session_state.user_input = ""
        st.rerun()  # Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù„Ø¥Ø¸Ù‡Ø§Ø± Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©

    else:
        st.session_state.user_input = user_input  # Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ù†Øµ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ù„Ùˆ Ù„Ù… ÙŠÙØ±Ø³Ù„

if __name__ == "__main__":
    app()
