import streamlit as st
import json
import re
from transformers import pipeline
import nest_asyncio


nest_asyncio.apply()


@st.cache_resource
def load_surah_data(filepath="surah_info.json"):
    with open(filepath, "r", encoding="utf-8") as f:
        return json.load(f)

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ø³ÙˆØ±Ø© Ù…Ù† Ø§Ù„Ø³Ø¤Ø§Ù„
def extract_surah_name(question):
    match = re.search(r"Ø³ÙˆØ±Ø©\s+([\w]+)", question)
    return match.group(1) if match else None

# ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø³ÙŠØ§Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù†Øµ Ù…Ø®ØªØµØ± Ø¹Ù† Ø§Ù„Ø³ÙˆØ±Ø©)
def get_context_from_surah(surah_name, surah_data):
    for surah in surah_data:
        if surah_name == surah["name_ar"]:
            return (
                f"Ø³ÙˆØ±Ø© {surah['name_ar']} Ù‡ÙŠ Ø³ÙˆØ±Ø© {surah['revelation_place']}ØŒ "
                f"Ø¹Ø¯Ø¯ Ø¢ÙŠØ§ØªÙ‡Ø§ {surah['verses_count']}ØŒ "
                f"Ù†Ø²Ù„Øª ÙÙŠ {surah['revelation_time']}ØŒ "
                f"ÙˆØ§Ù„Ù‡Ø¯Ù Ù…Ù†Ù‡Ø§: {surah['reasons']}."
            )
    return ""

# ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ LLM Ù…Ù† Hugging Face (Ù…ÙˆØ¯ÙŠÙ„ ØªÙˆÙ„ÙŠØ¯ Ù†Øµ Ø¹Ø±Ø¨ÙŠ)
@st.cache_resource
def load_llm_model():
    return pipeline(
    "question-answering",
    model="Elgeish/bert-base-arabic-qa",
    tokenizer="Elgeish/bert-base-arabic-qa"
)

# ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚
def generate_response_with_llm(question, context, llm):
    prompt = f"Ø§Ù„Ø³Ø¤Ø§Ù„: {question}\nØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª: {context}\nØ§Ù„Ø¥Ø¬Ø§Ø¨Ø©:"
    result = llm(prompt, max_length=150, do_sample=True, num_return_sequences=1)
    # Ù†Ø§Ø®Ø¯ Ø§Ù„Ù†Øµ Ø¨Ø¹Ø¯ "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:"
    answer = result[0]['generated_text'].split("Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:")[-1].strip()
    return answer

# Ø§Ù„Ø´Ø§Øª Ø¨ÙˆØª (Ø¯Ù…Ø¬ ÙƒÙ„ Ø­Ø§Ø¬Ø©)
def generate_response(message, surah_data, llm):
    msg = message.strip()

    if "Ø§Ù„Ø³Ù„Ø§Ù…" in msg or "Ù…Ø±Ø­Ø¨Ø§" in msg:
        return "ÙˆØ¹Ù„ÙŠÙƒÙ… Ø§Ù„Ø³Ù„Ø§Ù…! Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙŠØ§ Ø±ÙÙŠÙ‚ØŒ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ ğŸ˜Š"

    if "Ø´ÙƒØ±Ø§" in msg or "Ù…ØªØ´ÙƒØ±" in msg:
        return "Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø­Ø¨ ÙˆØ§Ù„Ø³Ø¹Ø©! ÙŠØ³Ø¹Ø¯Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø£ÙŠ ÙˆÙ‚Øª ğŸŒŸ"

    surah_name = extract_surah_name(msg)
    if surah_name:
        context = get_context_from_surah(surah_name, surah_data)
        if context:
            return generate_response_with_llm(msg, context, llm)
        else:
            return f"Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø³ÙˆØ±Ø© {surah_name}."

    return "Ù„Ù… Ø£ÙÙ‡Ù… Ø³Ø¤Ø§Ù„Ùƒ ØªÙ…Ø§Ù…Ù‹Ø§ ğŸ¤”ØŒ Ø­Ø§ÙˆÙ„ ØªÙƒØªØ¨Ù‡ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£ÙˆØ¶Ø­ Ø£Ùˆ Ø§Ø³Ø£Ù„Ù†ÙŠ Ø¹Ù† Ø³ÙˆØ±Ø© Ù…Ø¹ÙŠÙ†Ø©."

# ÙˆØ§Ø¬Ù‡Ø© Streamlit
def app():
    st.title("ğŸ¤– Ø±ÙÙŠÙ‚ Ø§Ù„Ù‚Ø±Ø¢Ù† - Ø´Ø§Øª Ø¨ÙˆØª Ù…Ø¹ LLM")

    # ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆØ±
    surah_data = load_surah_data()

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
    llm = load_llm_model()

    # Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ§Ù„Ø±Ø¯ÙˆØ¯ Ù…Ø®Ø²Ù†Ø© ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    for user_msg, bot_msg in st.session_state.chat_history:
        st.markdown(f"ğŸ‘¤ **Ø£Ù†Øª**: {user_msg}")
        st.markdown(f"ğŸ¤– **Ø±ÙÙŠÙ‚**: {bot_msg}")

    # Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    user_input = st.text_input("ğŸ’¬ Ø£ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§:")

    if user_input:
        response = generate_response(user_input, surah_data, llm)
        st.session_state.chat_history.append((user_input, response))
        st.rerun()

if __name__ == "__main__":
    app()
