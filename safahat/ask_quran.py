import streamlit as st
from transformers import AutoTokenizer, AutoModelForQuestionAnswering
import torch

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© (ÙƒÙØ§Ø¡Ø© Ø£Ø¹Ù„Ù‰)
@st.cache_resource
def load_quran_qa_model():
    tokenizer = AutoTokenizer.from_pretrained("mohammed-elkomy/quran-qa")
    model = AutoModelForQuestionAnswering.from_pretrained("mohammed-elkomy/quran-qa")
    return tokenizer, model

tokenizer, model = load_quran_qa_model()

# ØµÙØ­Ø© Ø§Ø³Ø£Ù„ Ø¹Ù† Ø§Ù„Ù‚Ø±Ø¢Ù†
def app():
    st.title("ğŸ“– Ø§Ø³Ø£Ù„ Ø¹Ù† Ø§Ù„Ù‚Ø±Ø¢Ù†")

    st.markdown("ğŸ•Œ **Ø§ÙƒØªØ¨ Ø£ÙŠ Ø³Ø¤Ø§Ù„ Ù…ØªØ¹Ù„Ù‚ Ø¨Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…** Ù…Ø«Ù„:\n- ÙƒÙ… Ø¹Ø¯Ø¯ Ø¢ÙŠØ§Øª Ø³ÙˆØ±Ø© Ø§Ù„Ø¨Ù‚Ø±Ø©ØŸ\n- Ù‡Ù„ Ø³ÙˆØ±Ø© Ø§Ù„ØªÙƒØ§Ø«Ø± Ù…ÙƒÙŠØ© Ø£Ù… Ù…Ø¯Ù†ÙŠØ©ØŸ\n- Ù„Ù…Ø§ Ù†Ø²Ù„Øª Ø³ÙˆØ±Ø© Ø§Ù„Ø·Ù„Ø§Ù‚ØŸ")

    question = st.text_input("âœï¸ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§:")
    
    # ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ Ù†Øµ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø£Ùˆ Ø¬Ø²Ø¡ Ù…Ù†Ù‡ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙƒØ³ÙŠØ§Ù‚
    # Ù‡Ù†Ø§ Ø³Ù†Ø¶Ø¹ Ù…Ø«Ø§Ù„ Ù…Ø¨Ø³Ø· ÙÙ‚Ø·ØŒ Ù…Ù…ÙƒÙ† ØªØ­Ø³ÙŠÙ†Ù‡ Ù„Ø§Ø­Ù‚Ù‹Ø§
    default_context = """
        Ø§Ù„Ù… (1) Ø°ÙÙ°Ù„ÙÙƒÙ Ø§Ù„Ù’ÙƒÙØªÙØ§Ø¨Ù Ù„ÙØ§ Ø±ÙÙŠÙ’Ø¨Ù Û› ÙÙÙŠÙ‡Ù Û› Ù‡ÙØ¯Ù‹Ù‰ Ù„ÙÙ‘Ù„Ù’Ù…ÙØªÙÙ‘Ù‚ÙÙŠÙ†Ù (2) Ø§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù ÙŠÙØ¤Ù’Ù…ÙÙ†ÙÙˆÙ†Ù Ø¨ÙØ§Ù„Ù’ØºÙÙŠÙ’Ø¨Ù ÙˆÙÙŠÙÙ‚ÙÙŠÙ…ÙÙˆÙ†Ù Ø§Ù„ØµÙÙ‘Ù„ÙØ§Ø©Ù...
    """

    context = st.text_area("ğŸ“œ Ø§Ù„Ø³ÙŠØ§Ù‚ (ÙŠÙ…ÙƒÙ† ØªØ±ÙƒÙ‡ ÙØ§Ø±Øº Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ù‚Ø±Ø¢Ù†):", value=default_context, height=150)

    if st.button("ğŸ” Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"):
        if not question.strip():
            st.warning("Ù…Ù† ÙØ¶Ù„Ùƒ Ø£Ø¯Ø®Ù„ Ø³Ø¤Ø§Ù„.")
        else:
            inputs = tokenizer.encode_plus(question, context, return_tensors="pt", truncation=True)
            with torch.no_grad():
                outputs = model(**inputs)
                answer_start = torch.argmax(outputs.start_logits)
                answer_end = torch.argmax(outputs.end_logits) + 1
                answer_ids = inputs["input_ids"][0][answer_start:answer_end]
                answer = tokenizer.decode(answer_ids, skip_special_tokens=True)
            st.success(f"ğŸ’¡ **Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:** {answer}")
