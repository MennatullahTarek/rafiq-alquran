import streamlit as st
import json
import re
from transformers import pipeline
import nest_asyncio



nest_asyncio.apply()

PRIMARY_COLOR = "#2E7D32"  # Ø£Ø®Ø¶Ø±
ACCENT_COLOR = "#FFC107"   # Ø°Ù‡Ø¨ÙŠ
BACKGROUND_COLOR = "#fffbf2"

@st.cache_resource
def load_surah_data(filepath="surah_info.json"):
    with open(filepath, "r", encoding="utf-8") as f:
        return json.load(f)

def extract_surah_name(question):
    match = re.search(r"Ø³ÙˆØ±Ø©\s+([\w]+)", question)
    return match.group(1) if match else None

def get_context_from_surah(surah_name, surah_data):
    for surah in surah_data:
        if surah_name == surah["name_ar"]:
            return (
                f"Ø³ÙˆØ±Ø© {surah['name_ar']} Ù‡ÙŠ Ø³ÙˆØ±Ø© {surah['revelation_place']}ØŒ "
                f"Ø¹Ø¯Ø¯ Ø¢ÙŠØ§ØªÙ‡Ø§ {surah['verses_count']}ØŒ "
                f"Ù†Ø²Ù„Øª ÙÙŠ {surah['revelation_time']}ØŒ "
                f"ÙˆØ§Ù„Ù‡Ø¯Ù Ù…Ù†Ù‡Ø§: {surah['reasons']}."
            )
    return ""

@st.cache_resource
def load_llm_model():
    with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºØ©... ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±"):
        model = pipeline("question-answering", model="Damith/AraELECTRA-discriminator-QuranQA")
    return model

def generate_response_with_llm(question, context, llm):
    if not context:
        return "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„."
    result = llm(question=question, context=context)
    return result["answer"]

def generate_response(message, surah_data, llm):
    msg = message.strip()

    if "Ø§Ù„Ø³Ù„Ø§Ù…" in msg or "Ù…Ø±Ø­Ø¨Ø§" in msg:
        return "ÙˆØ¹Ù„ÙŠÙƒÙ… Ø§Ù„Ø³Ù„Ø§Ù…! Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙŠØ§ Ø±ÙÙŠÙ‚ØŒ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ ğŸ˜Š"

    if "Ø´ÙƒØ±Ø§" in msg or "Ù…ØªØ´ÙƒØ±" in msg:
        return "Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø­Ø¨ ÙˆØ§Ù„Ø³Ø¹Ø©! ÙŠØ³Ø¹Ø¯Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø£ÙŠ ÙˆÙ‚Øª ğŸŒŸ"

    surah_name = extract_surah_name(msg)
    if surah_name:
        context = get_context_from_surah(surah_name, surah_data)
        if context:
            return generate_response_with_llm(msg, context, llm)
        else:
            return f"Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø³ÙˆØ±Ø© {surah_name}."

    return "Ù„Ù… Ø£ÙÙ‡Ù… Ø³Ø¤Ø§Ù„Ùƒ ØªÙ…Ø§Ù…Ù‹Ø§ ğŸ¤”ØŒ Ø­Ø§ÙˆÙ„ ØªÙƒØªØ¨Ù‡ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£ÙˆØ¶Ø­ Ø£Ùˆ Ø§Ø³Ø£Ù„Ù†ÙŠ Ø¹Ù† Ø³ÙˆØ±Ø© Ù…Ø¹ÙŠÙ†Ø©."

def render_message(user_msg, bot_msg):
    message_html = f"""
    <style>
    .chat-container {{
        max-width: 700px;
        margin: 0 auto 10px auto;
        font-family:  'Cairo', sans-serif;
        background-color: {BACKGROUND_COLOR};
        padding: 10px 20px;
        border-radius: 12px;
    }}
    .message {{
        display: flex;
        margin-bottom: 12px;
        align-items: flex-start;
    }}
    .user-msg {{
        justify-content: flex-start;
    }}
    .bot-msg {{
        justify-content: flex-end;
    }}
    .bubble {{
        max-width: 70%;
        padding: 12px 18px;
        border-radius: 18px;
        font-size: 16px;
        line-height: 1.4;
        white-space: pre-wrap;
        word-wrap: break-word;
    }}
    .user-bubble {{
        background-color: #DCF8C6;
        color: #000;
        border-bottom-left-radius: 0;
    }}
    .bot-bubble {{
        background-color: {ACCENT_COLOR};
        color: #000;
        border-bottom-right-radius: 0;
    }}
    .user-icon {{
        font-weight: bold;
        margin-right: 10px;
        color: {PRIMARY_COLOR};
        min-width: 30px;
        text-align: center;
    }}
    .bot-icon {{
        font-weight: bold;
        margin-left: 10px;
        color: #5a4b00;
        min-width: 30px;
        text-align: center;
    }}
    </style>

    <div class="chat-container">
        <div class="message user-msg">
            <div class="user-icon">ğŸ‘¤</div>
            <div class="bubble user-bubble">{user_msg}</div>
        </div>
        <div class="message bot-msg">
            <div class="bubble bot-bubble">{bot_msg}</div>
            <div class="bot-icon">ğŸ¤–</div>
        </div>
    </div>
    """
    st.markdown(message_html, unsafe_allow_html=True)

def on_enter():
    user_input = st.session_state.user_input.strip()
    if user_input:
        response = generate_response(user_input, st.session_state.surah_data, st.session_state.qa_pipeline)
        st.session_state.chat_history.append((user_input, response))
        st.session_state.user_input = ""

def app():
    st.markdown(
        f"""
        <h1 style="text-align: center; color: {PRIMARY_COLOR}; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;">
        ğŸ¤– Ø±ÙÙŠÙ‚ Ø§Ù„Ù‚Ø±Ø¢Ù† - Ø´Ø§Øª Ø¨ÙˆØª Ù…Ø¹ QA
        </h1>
        """,
        unsafe_allow_html=True,
    )

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "user_input" not in st.session_state:
        st.session_state.user_input = ""

    if "surah_data" not in st.session_state:
        st.session_state.surah_data = load_surah_data()
    if "qa_pipeline" not in st.session_state:
        st.session_state.qa_pipeline = load_llm_model()

    # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¨Ø´ÙƒÙ„ ÙÙ‚Ø§Ø¹Ø§Øª
    if st.session_state.chat_history:
        for user_msg, bot_msg in st.session_state.chat_history:
            render_message(user_msg, bot_msg)

    # Ù†Øµ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ù…Ø¹ on_change Ø¹Ø´Ø§Ù† Ù†Ø±Ø³Ù„ Ø¨Ø§Ù„Ø¶ØºØ· Enter
    st.text_input(
        "ğŸ’¬ Ø£ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§:",
        key="user_input",
        on_change=on_enter,
        placeholder="Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ ÙˆØ§Ø¶ØºØ· Enter Ù„Ù„Ø¥Ø±Ø³Ø§Ù„...",
        label_visibility="collapsed"
    )

if __name__ == "__main__":
    app()
