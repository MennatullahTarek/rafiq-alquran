import streamlit as st
import requests
import difflib
import re
import csv
from io import StringIO
from huggingface_hub import InferenceClient

# Agent 4: LLM
class LLMHelper:
    def __init__(self, hf_token, model="tiiuae/falcon-7b-instruct"):
        self.client = InferenceClient(token=hf_token)
        self.model = model

    def ask(self, prompt):
        response = self.client.text_generation(
            model=self.model,
            prompt=prompt,
            max_new_tokens=100,
            temperature=0.7
        )
        return response

# Agent 1: Ø³ÙˆØ± ÙˆØ¢ÙŠØ§Øª
def get_surahs():
    return {
        "Ø§Ù„ÙØ§ØªØ­Ø©": 1, "Ø§Ù„Ø¨Ù‚Ø±Ø©": 2, "Ø¢Ù„ Ø¹Ù…Ø±Ø§Ù†": 3, "Ø§Ù„Ù†Ø³Ø§Ø¡": 4, "Ø§Ù„Ù…Ø§Ø¦Ø¯Ø©": 5, "Ø§Ù„Ø£Ù†Ø¹Ø§Ù…": 6, "Ø§Ù„Ø£Ø¹Ø±Ø§Ù": 7,
        "Ø§Ù„Ø£Ù†ÙØ§Ù„": 8, "Ø§Ù„ØªÙˆØ¨Ø©": 9, "ÙŠÙˆÙ†Ø³": 10, "Ù‡ÙˆØ¯": 11, "ÙŠÙˆØ³Ù": 12, "Ø§Ù„Ø±Ø¹Ø¯": 13, "Ø¥Ø¨Ø±Ø§Ù‡ÙŠÙ…": 14,
        "Ø§Ù„Ø­Ø¬Ø±": 15, "Ø§Ù„Ù†Ø­Ù„": 16, "Ø§Ù„Ø¥Ø³Ø±Ø§Ø¡": 17, "Ø§Ù„ÙƒÙ‡Ù": 18, "Ù…Ø±ÙŠÙ…": 19, "Ø·Ù‡": 20, "Ø§Ù„Ø£Ù†Ø¨ÙŠØ§Ø¡": 21,
        "Ø§Ù„Ø­Ø¬": 22, "Ø§Ù„Ù…Ø¤Ù…Ù†ÙˆÙ†": 23, "Ø§Ù„Ù†ÙˆØ±": 24, "Ø§Ù„ÙØ±Ù‚Ø§Ù†": 25, "Ø§Ù„Ø´Ø¹Ø±Ø§Ø¡": 26, "Ø§Ù„Ù†Ù…Ù„": 27, "Ø§Ù„Ù‚ØµØµ": 28,
        "Ø§Ù„Ø¹Ù†ÙƒØ¨ÙˆØª": 29, "Ø§Ù„Ø±ÙˆÙ…": 30, "Ù„Ù‚Ù…Ø§Ù†": 31, "Ø§Ù„Ø³Ø¬Ø¯Ø©": 32, "Ø§Ù„Ø£Ø­Ø²Ø§Ø¨": 33, "Ø³Ø¨Ø£": 34, "ÙØ§Ø·Ø±": 35,
        "ÙŠØ³": 36, "Ø§Ù„ØµØ§ÙØ§Øª": 37, "Øµ": 38, "Ø§Ù„Ø²Ù…Ø±": 39, "ØºØ§ÙØ±": 40, "ÙØµÙ„Øª": 41, "Ø§Ù„Ø´ÙˆØ±Ù‰": 42, "Ø§Ù„Ø²Ø®Ø±Ù": 43,
        "Ø§Ù„Ø¯Ø®Ø§Ù†": 44, "Ø§Ù„Ø¬Ø§Ø«ÙŠØ©": 45, "Ø§Ù„Ø£Ø­Ù‚Ø§Ù": 46, "Ù…Ø­Ù…Ø¯": 47, "Ø§Ù„ÙØªØ­": 48, "Ø§Ù„Ø­Ø¬Ø±Ø§Øª": 49, "Ù‚": 50,
        "Ø§Ù„Ø°Ø§Ø±ÙŠØ§Øª": 51, "Ø§Ù„Ø·ÙˆØ±": 52, "Ø§Ù„Ù†Ø¬Ù…": 53, "Ø§Ù„Ù‚Ù…Ø±": 54, "Ø§Ù„Ø±Ø­Ù…Ù†": 55, "Ø§Ù„ÙˆØ§Ù‚Ø¹Ø©": 56, "Ø§Ù„Ø­Ø¯ÙŠØ¯": 57,
        "Ø§Ù„Ù…Ø¬Ø§Ø¯Ù„Ø©": 58, "Ø§Ù„Ø­Ø´Ø±": 59, "Ø§Ù„Ù…Ù…ØªØ­Ù†Ø©": 60, "Ø§Ù„ØµÙ": 61, "Ø§Ù„Ø¬Ù…Ø¹Ø©": 62, "Ø§Ù„Ù…Ù†Ø§ÙÙ‚ÙˆÙ†": 63, "Ø§Ù„ØªØºØ§Ø¨Ù†": 64,
        "Ø§Ù„Ø·Ù„Ø§Ù‚": 65, "Ø§Ù„ØªØ­Ø±ÙŠÙ…": 66, "Ø§Ù„Ù…Ù„Ùƒ": 67, "Ø§Ù„Ù‚Ù„Ù…": 68, "Ø§Ù„Ø­Ø§Ù‚Ø©": 69, "Ø§Ù„Ù…Ø¹Ø§Ø±Ø¬": 70, "Ù†ÙˆØ­": 71,
        "Ø§Ù„Ø¬Ù†": 72, "Ø§Ù„Ù…Ø²Ù…Ù„": 73, "Ø§Ù„Ù…Ø¯Ø«Ø±": 74, "Ø§Ù„Ù‚ÙŠØ§Ù…Ø©": 75, "Ø§Ù„Ø¥Ù†Ø³Ø§Ù†": 76, "Ø§Ù„Ù…Ø±Ø³Ù„Ø§Øª": 77, "Ø§Ù„Ù†Ø¨Ø£": 78,
        "Ø§Ù„Ù†Ø§Ø²Ø¹Ø§Øª": 79, "Ø¹Ø¨Ø³": 80, "Ø§Ù„ØªÙƒÙˆÙŠØ±": 81, "Ø§Ù„Ø¥Ù†ÙØ·Ø§Ø±": 82, "Ø§Ù„Ù…Ø·ÙÙÙŠÙ†": 83, "Ø§Ù„Ø§Ù†Ø´Ù‚Ø§Ù‚": 84, "Ø§Ù„Ø¨Ø±ÙˆØ¬": 85,
        "Ø§Ù„Ø·Ø§Ø±Ù‚": 86, "Ø§Ù„Ø£Ø¹Ù„Ù‰": 87, "Ø§Ù„ØºØ§Ø´ÙŠØ©": 88, "Ø§Ù„ÙØ¬Ø±": 89, "Ø§Ù„Ø¨Ù„Ø¯": 90, "Ø§Ù„Ø´Ù…Ø³": 91, "Ø§Ù„Ù„ÙŠÙ„": 92,
        "Ø§Ù„Ø¶Ø­Ù‰": 93, "Ø§Ù„Ø´Ø±Ø­": 94, "Ø§Ù„ØªÙŠÙ†": 95, "Ø§Ù„Ø¹Ù„Ù‚": 96, "Ø§Ù„Ù‚Ø¯Ø±": 97, "Ø§Ù„Ø¨ÙŠÙ†Ø©": 98, "Ø§Ù„Ø²Ù„Ø²Ù„Ø©": 99,
        "Ø§Ù„Ø¹Ø§Ø¯ÙŠØ§Øª": 100, "Ø§Ù„Ù‚Ø§Ø±Ø¹Ø©": 101, "Ø§Ù„ØªÙƒØ§Ø«Ø±": 102, "Ø§Ù„Ø¹ØµØ±": 103, "Ø§Ù„Ù‡Ù…Ø²Ø©": 104, "Ø§Ù„ÙÙŠÙ„": 105, "Ù‚Ø±ÙŠØ´": 106,
        "Ø§Ù„Ù…Ø§Ø¹ÙˆÙ†": 107, "Ø§Ù„ÙƒÙˆØ«Ø±": 108, "Ø§Ù„ÙƒØ§ÙØ±ÙˆÙ†": 109, "Ø§Ù„Ù†ØµØ±": 110, "Ø§Ù„Ù…Ø³Ø¯": 111, "Ø§Ù„Ø¥Ø®Ù„Ø§Øµ": 112,
        "Ø§Ù„ÙÙ„Ù‚": 113, "Ø§Ù„Ù†Ø§Ø³": 114
    }

def get_ayah_text(surah, ayah):
    url = f"https://api.quran.com/api/v4/quran/verses/uthmani?verse_key={surah}:{ayah}"
    response = requests.get(url)
    if response.status_code == 200:
        try:
            return response.json()['verses'][0]['text_uthmani']
        except (KeyError, IndexError):
            return "âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Øµ Ø§Ù„Ø¢ÙŠØ©."
    return "âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù†Øµ Ø§Ù„Ø¢ÙŠØ©."

# Agent 2: ØªÙØ³ÙŠØ±

def get_tafsir(surah, ayah, tafsir_id=91):
    url = f"https://api.quran.com/api/v4/tafsirs/{tafsir_id}/by_ayah/{surah}:{ayah}"
    response = requests.get(url)
    if response.status_code == 200:
        try:
            return response.json()['tafsir']['text']
        except (KeyError, TypeError):
            return "âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ³ÙŠØ±."
    return "âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„ØªÙØ³ÙŠØ±."

# Ø£Ø¯ÙˆØ§Øª ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø­ÙØ¸

def strip_tashkeel(text):
    return re.sub(r'[\u064B-\u0652]', '', text)

def compare_ayah(user_input, actual_text):
    actual_clean = strip_tashkeel(actual_text.replace('\n', '').strip())
    user_clean = user_input.replace('\n', '').strip()
    ratio = difflib.SequenceMatcher(None, actual_clean, user_clean).ratio()
    return round(ratio * 100, 2)

# Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ

def app():
    st.set_page_config(page_title="Ø±ÙÙŠÙ‚ Ø§Ù„Ù‚Ø±Ø¢Ù†")
    st.title("ğŸ“– Ø±ÙÙŠÙ‚ Ø§Ù„Ù‚Ø±Ø¢Ù† - Ù…Ø±Ø§Ø¬Ø¹Ø© ÙˆØ­ÙØ¸ ÙˆØªÙØ³ÙŠØ±")

    hf_token = st.secrets["hf_token"]
    llm_helper = LLMHelper(hf_token)
    surahs = get_surahs()

    surah_name = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø³ÙˆØ±Ø©", list(surahs.keys()))
    start_ayah = st.number_input("Ù…Ù† Ø§Ù„Ø¢ÙŠØ© Ø±Ù‚Ù…", min_value=1, value=1)
    end_ayah = st.number_input("Ø¥Ù„Ù‰ Ø§Ù„Ø¢ÙŠØ© Ø±Ù‚Ù…", min_value=start_ayah, value=start_ayah)

    if "responses" not in st.session_state:
        st.session_state.responses = []

    if st.button("Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø¥Ø®ØªØ¨Ø§Ø±"):
        for ayah_num in range(start_ayah, end_ayah + 1):
            st.subheader(f"Ø§Ù„Ø¢ÙŠØ© {ayah_num}")
            actual_ayah = get_ayah_text(surahs[surah_name], ayah_num)
            tafsir = get_tafsir(surahs[surah_name], ayah_num)

            st.markdown("### ğŸ§  Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø­ÙØ¸")
            # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ ÙƒÙ… ÙƒÙ„Ù…Ø© Ù…Ù† Ø§Ù„Ø¢ÙŠØ© ÙƒÙ…Ø­ÙØ²
            words = actual_ayah.split(" ")
            clue = " ".join(words[:2]) + " ..."
            st.markdown(f"#### ğŸ‘‡ Ø£ÙƒÙ…Ù„ Ø¨Ø¹Ø¯: `{clue}`")

            user_mem = st.text_area(f"Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ø¢ÙŠØ© ({ayah_num}):", key=f"mem_{ayah_num}")

            score = correction = "-"
            if user_mem:
                score = compare_ayah(user_mem, actual_ayah)
                st.markdown(f"âœ… ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø­ÙØ¸: **{score}%**")

            st.markdown("### ğŸ“˜ Ø§Ù„ØªÙØ³ÙŠØ±")
            user_tafsir = st.text_area(f"Ø§Ø´Ø±Ø­ Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø¢ÙŠØ© Ø£Ùˆ Ø§Ù„ÙƒÙ„Ù…Ø§Øª ({ayah_num}):", key=f"tafsir_{ayah_num}")
            if user_tafsir:
                prompt = f"Ù‚Ø§Ø±Ù† Ø§Ù„ØªÙØ³ÙŠØ± Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø§Ù„ØªÙØ³ÙŠØ± Ø§Ù„Ø±Ø³Ù…ÙŠ: '{user_tafsir}'. Ø§Ù„ØªÙØ³ÙŠØ± Ø§Ù„Ø±Ø³Ù…ÙŠ: '{tafsir}'. Ù‚ÙŠÙ…Ù‡ Ù…Ù† Ù¡Ù  Ù…Ø¹ ØªØµØ­ÙŠØ­ Ø§Ù„Ø®Ø·Ø£."
                correction = llm_helper.ask(prompt)
                st.markdown("ğŸ§¾ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªÙØ³ÙŠØ±:")
                st.write(correction)

            st.session_state.responses.append([
                surah_name,
                ayah_num,
                user_mem,
                f"{score}%",
                user_tafsir,
                correction
            ])

        csv_buffer = StringIO()
        writer = csv.writer(csv_buffer)
        writer.writerow(["Ø§Ù„Ø³ÙˆØ±Ø©", "Ø±Ù‚Ù… Ø§Ù„Ø¢ÙŠØ©", "Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø­ÙØ¸", "ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø­ÙØ¸", "Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªÙØ³ÙŠØ±", "ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªÙØ³ÙŠØ±"])
        writer.writerows(st.session_state.responses)

        st.download_button(
            label="ğŸ’¾ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø©",
            data=csv_buffer.getvalue(),
            file_name="quran_review_results.csv",
            mime="text/csv"
        )
