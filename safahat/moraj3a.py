import streamlit as st
import requests
import csv
from io import StringIO
from huggingface_hub import InferenceClient


surahs = {
    "Ø§Ù„ÙØ§ØªØ­Ø©": 1,
    "Ø§Ù„Ø¨Ù‚Ø±Ø©": 2,
    "Ø¢Ù„ Ø¹Ù…Ø±Ø§Ù†": 3,
    "Ø§Ù„Ù†Ø³Ø§Ø¡": 4,
    "Ø§Ù„Ù…Ø§Ø¦Ø¯Ø©": 5,
    "Ø§Ù„Ø£Ù†Ø¹Ø§Ù…": 6,
    "Ø§Ù„Ø£Ø¹Ø±Ø§Ù": 7,
    "Ø§Ù„Ø£Ù†ÙØ§Ù„": 8,
    "Ø§Ù„ØªÙˆØ¨Ø©": 9,
    "ÙŠÙˆÙ†Ø³": 10,
    "Ù‡ÙˆØ¯": 11,
    "ÙŠÙˆØ³Ù": 12,
    "Ø§Ù„Ø±Ø¹Ø¯": 13,
    "Ø¥Ø¨Ø±Ø§Ù‡ÙŠÙ…": 14,
    "Ø§Ù„Ø­Ø¬Ø±": 15,
    "Ø§Ù„Ù†Ø­Ù„": 16,
    "Ø§Ù„Ø¥Ø³Ø±Ø§Ø¡": 17,
    "Ø§Ù„ÙƒÙ‡Ù": 18,
    "Ù…Ø±ÙŠÙ…": 19,
    "Ø·Ù‡": 20,
    "Ø§Ù„Ø£Ù†Ø¨ÙŠØ§Ø¡": 21,
    "Ø§Ù„Ø­Ø¬": 22,
    "Ø§Ù„Ù…Ø¤Ù…Ù†ÙˆÙ†": 23,
    "Ø§Ù„Ù†ÙˆØ±": 24,
    "Ø§Ù„ÙØ±Ù‚Ø§Ù†": 25,
    "Ø§Ù„Ø´Ø¹Ø±Ø§Ø¡": 26,
    "Ø§Ù„Ù†Ù…Ù„": 27,
    "Ø§Ù„Ù‚ØµØµ": 28,
    "Ø§Ù„Ø¹Ù†ÙƒØ¨ÙˆØª": 29,
    "Ø§Ù„Ø±ÙˆÙ…": 30,
    "Ù„Ù‚Ù…Ø§Ù†": 31,
    "Ø§Ù„Ø³Ø¬Ø¯Ø©": 32,
    "Ø§Ù„Ø£Ø­Ø²Ø§Ø¨": 33,
    "Ø³Ø¨Ø£": 34,
    "ÙØ§Ø·Ø±": 35,
    "ÙŠØ³": 36,
    "Ø§Ù„ØµØ§ÙØ§Øª": 37,
    "Øµ": 38,
    "Ø§Ù„Ø²Ù…Ø±": 39,
    "ØºØ§ÙØ±": 40,
    "ÙØµÙ„Øª": 41,
    "Ø§Ù„Ø´ÙˆØ±Ù‰": 42,
    "Ø§Ù„Ø²Ø®Ø±Ù": 43,
    "Ø§Ù„Ø¯Ø®Ø§Ù†": 44,
    "Ø§Ù„Ø¬Ø§Ø«ÙŠØ©": 45,
    "Ø§Ù„Ø£Ø­Ù‚Ø§Ù": 46,
    "Ù…Ø­Ù…Ø¯": 47,
    "Ø§Ù„ÙØªØ­": 48,
    "Ø§Ù„Ø­Ø¬Ø±Ø§Øª": 49,
    "Ù‚": 50,
    "Ø§Ù„Ø°Ø§Ø±ÙŠØ§Øª": 51,
    "Ø§Ù„Ø·ÙˆØ±": 52,
    "Ø§Ù„Ù†Ø¬Ù…": 53,
    "Ø§Ù„Ù‚Ù…Ø±": 54,
    "Ø§Ù„Ø±Ø­Ù…Ù†": 55,
    "Ø§Ù„ÙˆØ§Ù‚Ø¹Ø©": 56,
    "Ø§Ù„Ø­Ø¯ÙŠØ¯": 57,
    "Ø§Ù„Ù…Ø¬Ø§Ø¯Ù„Ø©": 58,
    "Ø§Ù„Ø­Ø´Ø±": 59,
    "Ø§Ù„Ù…Ù…ØªØ­Ù†Ø©": 60,
    "Ø§Ù„ØµÙ": 61,
    "Ø§Ù„Ø¬Ù…Ø¹Ø©": 62,
    "Ø§Ù„Ù…Ù†Ø§ÙÙ‚ÙˆÙ†": 63,
    "Ø§Ù„ØªØºØ§Ø¨Ù†": 64,
    "Ø§Ù„Ø·Ù„Ø§Ù‚": 65,
    "Ø§Ù„ØªØ­Ø±ÙŠÙ…": 66,
    "Ø§Ù„Ù…Ù„Ùƒ": 67,
    "Ø§Ù„Ù‚Ù„Ù…": 68,
    "Ø§Ù„Ø­Ø§Ù‚Ø©": 69,
    "Ø§Ù„Ù…Ø¹Ø§Ø±Ø¬": 70,
    "Ù†ÙˆØ­": 71,
    "Ø§Ù„Ø¬Ù†": 72,
    "Ø§Ù„Ù…Ø²Ù‘Ù…Ù‘Ù„": 73,
    "Ø§Ù„Ù…Ø¯Ù‘Ø«Ø±": 74,
    "Ø§Ù„Ù‚ÙŠØ§Ù…Ø©": 75,
    "Ø§Ù„Ø¥Ù†Ø³Ø§Ù†": 76,
    "Ø§Ù„Ù…Ø±Ø³Ù„Ø§Øª": 77,
    "Ø§Ù„Ù†Ø¨Ø£": 78,
    "Ø§Ù„Ù†Ø§Ø²Ø¹Ø§Øª": 79,
    "Ø¹Ø¨Ø³": 80,
    "Ø§Ù„ØªÙƒÙˆÙŠØ±": 81,
    "Ø§Ù„Ø¥Ù†ÙØ·Ø§Ø±": 82,
    "Ø§Ù„Ù…Ø·ÙÙ‘ÙÙŠÙ†": 83,
    "Ø§Ù„Ø¥Ù†Ø´Ù‚Ø§Ù‚": 84,
    "Ø§Ù„Ø¨Ø±ÙˆØ¬": 85,
    "Ø§Ù„Ø·Ø§Ø±Ù‚": 86,
    "Ø§Ù„Ø£Ø¹Ù„Ù‰": 87,
    "Ø§Ù„ØºØ§Ø´ÙŠØ©": 88,
    "Ø§Ù„ÙØ¬Ø±": 89,
    "Ø§Ù„Ø¨Ù„Ø¯": 90,
    "Ø§Ù„Ø´Ù…Ø³": 91,
    "Ø§Ù„Ù„ÙŠÙ„": 92,
    "Ø§Ù„Ø¶Ø­Ù‰": 93,
    "Ø§Ù„Ø´Ø±Ø­": 94,
    "Ø§Ù„ØªÙŠÙ†": 95,
    "Ø§Ù„Ø¹Ù„Ù‚": 96,
    "Ø§Ù„Ù‚Ø¯Ø±": 97,
    "Ø§Ù„Ø¨ÙŠÙ†Ø©": 98,
    "Ø§Ù„Ø²Ù„Ø²Ù„Ø©": 99,
    "Ø§Ù„Ø¹Ø§Ø¯ÙŠØ§Øª": 100,
    "Ø§Ù„Ù‚Ø§Ø±Ø¹Ø©": 101,
    "Ø§Ù„ØªÙƒØ§Ø«Ø±": 102,
    "Ø§Ù„Ø¹ØµØ±": 103,
    "Ø§Ù„Ù‡Ù…Ø²Ø©": 104,
    "Ø§Ù„ÙÙŠÙ„": 105,
    "Ù‚Ø±ÙŠØ´": 106,
    "Ø§Ù„Ù…Ø§Ø¹ÙˆÙ†": 107,
    "Ø§Ù„ÙƒÙˆØ«Ø±": 108,
    "Ø§Ù„ÙƒØ§ÙØ±ÙˆÙ†": 109,
    "Ø§Ù„Ù†ØµØ±": 110,
    "Ø§Ù„Ù…Ø³Ø¯": 111,
    "Ø§Ù„Ø¥Ø®Ù„Ø§Øµ": 112,
    "Ø§Ù„ÙÙ„Ù‚": 113,
    "Ø§Ù„Ù†Ø§Ø³": 114
}



def get_ayah_text(surah_num, ayah_num):
    url = f"https://api.quran.com/api/v4/quran/verses/uthmani?verse_key={surah_num}:{ayah_num}"
    r = requests.get(url)
    if r.status_code == 200:
        data = r.json()
        try:
            return data['verses'][0]['text_uthmani']
        except (KeyError, IndexError):
            return None
    return None

def get_tafsir(surah_num, ayah_num, tafsir_id=91):  # tafsir_id 91: ØªÙØ³ÙŠØ± Ø§Ø¨Ù† ÙƒØ«ÙŠØ±
    url = f"https://api.quran.com/api/v4/tafsirs/{tafsir_id}/by_ayah/{surah_num}:{ayah_num}"
    r = requests.get(url)
    if r.status_code == 200:
        try:
            return r.json()['tafsir']['text']
        except (KeyError, TypeError):
            return None
    return None

# --  (Agents) --

class DataAgent:
    def __init__(self, surah_name, start_ayah, end_ayah):
        self.surah_name = surah_name
        self.surah_num = surahs[surah_name]
        self.start_ayah = start_ayah
        self.end_ayah = end_ayah
        self.current_ayah = start_ayah

    def get_current_ayah(self):
        return get_ayah_text(self.surah_num, self.current_ayah)

    def get_current_tafsir(self):
        return get_tafsir(self.surah_num, self.current_ayah)

    def next_ayah(self):
        if self.current_ayah < self.end_ayah:
            self.current_ayah += 1
            return True
        return False

class MemorizationAgent:
    def __init__(self, surah_num, start_ayah, end_ayah):
        self.surah_num = surah_num
        self.start_ayah = start_ayah
        self.end_ayah = end_ayah

    def check_ayah(self, ayah_num, user_text):
        correct_text = get_ayah_text(self.surah_num, ayah_num)
        if not correct_text:
            return False, "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø¬Ù„Ø¨ Ù†Øµ Ø§Ù„Ø¢ÙŠØ©."
        # Ù…Ù‚Ø§Ø±Ù†Ø© Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„ØµØ­ÙŠØ­ (Ù…Ù…ÙƒÙ† ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹)
        if user_text.strip() == correct_text.strip():
            return True, "Ø¥Ø¬Ø§Ø¨ØªÙƒ ØµØ­ÙŠØ­Ø©."
        else:
            return False, f"Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ØºÙŠØ± ØµØ­ÙŠØ­Ø©.\nØ§Ù„Ù†Øµ Ø§Ù„ØµØ­ÙŠØ­:\n{correct_text}"

class TafsirAgent:
    def __init__(self, surah_num):
        self.surah_num = surah_num

    def check_tafsir(self, ayah_num, user_tafsir):
        correct_tafsir = get_tafsir(self.surah_num, ayah_num)
        if not correct_tafsir:
            return False, "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø¬Ù„Ø¨ Ø§Ù„ØªÙØ³ÙŠØ±."
        # Ù‡Ù†Ø§ Ù…Ù…ÙƒÙ† Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø°ÙƒÙŠØ©ØŒ Ù„ÙƒÙ† Ø­Ø§Ù„ÙŠØ§Ù‹ Ù…Ù‚Ø§Ø±Ù†Ø© Ù†ØµÙŠØ© Ø¨Ø³ÙŠØ·Ø©:
        user_tafsir = user_tafsir.strip()
        if user_tafsir in correct_tafsir:
            return True, "ØªÙØ³ÙŠØ±Ùƒ Ù…Ù‚Ø¨ÙˆÙ„."
        else:
            return False, "Ø§Ù„ØªÙØ³ÙŠØ± ÙŠØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø©."

class LLMHelper:
    def __init__(self, token, model="bigscience/bloom"):
        self.client = InferenceClient(token=token)
        self.model = model

    def ask(self, prompt):
        response = self.client.text_generation(
            model=self.model,
            prompt=prompt,
            max_new_tokens=100
        )
        # response Ù‡ÙŠ dict ÙÙŠÙ‡Ø§ key 'generated_text'
        return response.get('generated_text', '').strip()



def app():
    st.title("ğŸ“– Ø§Ø®ØªØ¨Ø§Ø± Ø­ÙØ¸ ÙˆØªÙØ³ÙŠØ± Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…")

 
    if "data_agent" not in st.session_state:
        st.session_state.data_agent = None
    if "memorization_agent" not in st.session_state:
        st.session_state.memorization_agent = None
    if "tafsir_agent" not in st.session_state:
        st.session_state.tafsir_agent = None
    if "llm_helper" not in st.session_state:
        # Ù…Ø§ ØªØ¶ÙŠÙØ´ Ø§Ù„ØªÙˆÙƒÙ† Ù‡Ù†Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©ØŒ Ø®Ù„ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ­Ø· Ø§Ù„ØªÙˆÙƒÙ† Ø£Ùˆ Ø­Ø· Ù…Ù† env vars
        st.session_state.llm_helper = None

    if st.session_state.data_agent is None:
        # Ø¥Ø¯Ø®Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
        surah_name = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø³ÙˆØ±Ø©", list(surahs.keys()))
        start_ayah = st.number_input("Ø±Ù‚Ù… Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø¢ÙŠØ©", min_value=1, value=1)
        end_ayah = st.number_input("Ø±Ù‚Ù… Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø¢ÙŠØ©", min_value=start_ayah, value=start_ayah)

        token = st.text_input("Ø£Ø¯Ø®Ù„ Huggingface Token (Ù„Ø§ ÙŠØ¸Ù‡Ø±)", type="password")

        if st.button("Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±"):
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡
            st.session_state.data_agent = DataAgent(surah_name, start_ayah, end_ayah)
            st.session_state.memorization_agent = MemorizationAgent(surahs[surah_name], start_ayah, end_ayah)
            st.session_state.tafsir_agent = TafsirAgent(surahs[surah_name])
            if token.strip() != "":
                st.session_state.llm_helper = LLMHelper(token.strip())
            else:
                st.warning("ÙŠÙÙØ¶Ù„ Ø¥Ø¯Ø®Ø§Ù„ ØªÙˆÙƒÙ† Huggingface Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")

            st.experimental_rerun()

    else:
        data_agent = st.session_state.data_agent
        mem_agent = st.session_state.memorization_agent
        tafsir_agent = st.session_state.tafsir_agent
        llm_helper = st.session_state.llm_helper

        current_ayah_num = data_agent.current_ayah
        st.markdown(f"### Ø§Ù„Ø³ÙˆØ±Ø©: **{data_agent.surah_name}** - Ø§Ù„Ø¢ÙŠØ© Ø±Ù‚Ù… {current_ayah_num}")

        
        ayah_text = data_agent.get_current_ayah()
        if ayah_text:
           
            halfway = len(ayah_text) // 2
            part_ayah = ayah_text[:halfway] + "..."
            st.markdown(f"**Ù†Øµ Ø§Ù„Ø¢ÙŠØ© (Ø¬Ø²Ø¡):** {part_ayah}")
        else:
            st.error("Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù†Øµ Ø§Ù„Ø¢ÙŠØ©")

        # Ø§Ù„ÙŠÙˆØ²Ø± ÙŠÙƒØªØ¨ ØªÙƒÙ…Ù„Ø© Ø§Ù„Ø¢ÙŠØ©
        user_memorization = st.text_area("Ø£ÙƒÙ…Ù„ Ù†Øµ Ø§Ù„Ø¢ÙŠØ© Ù…Ù† Ø¹Ù†Ø¯Ùƒ:", height=100)

        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø­ÙØ¸
        if st.button("ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­ÙØ¸"):
            if user_memorization.strip() == "":
                st.warning("Ù…Ù† ÙØ¶Ù„Ùƒ Ø§ÙƒØªØ¨ ØªÙƒÙ…Ù„Ø© Ø§Ù„Ø¢ÙŠØ©")
            else:
                correct, feedback = mem_agent.check_ayah(current_ayah_num, user_memorization)
                st.markdown(f"**Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø­ÙØ¸:** {feedback}")

                # Ø§Ø³ØªØ®Ø¯Ø§Ù… LLM Ù„ØªØµØ­ÙŠØ­ Ø§Ù„Ù†Øµ
                if llm_helper:
                    prompt = f"ØµØ­Ø­ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ù† Ø§Ù„Ù‚Ø±Ø¢Ù†: \"{user_memorization}\" ÙˆÙ‚Ù„ Ù„ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù† ØµØ­ÙŠØ­Ù‹Ø§ Ø£Ùˆ Ø¨Ù‡ Ø£Ø®Ø·Ø§Ø¡."
                    correction = llm_helper.ask(prompt)
                    st.markdown(f"**ØªØµØ­ÙŠØ­ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:** {correction}")

        # Ø·Ù„Ø¨ ØªÙØ³ÙŠØ± Ø§Ù„Ø¢ÙŠØ©
        user_tafsir = st.text_area("Ø§ÙƒØªØ¨ ØªÙØ³ÙŠØ±Ùƒ Ø£Ùˆ Ø´Ø±Ø­Ùƒ Ù„Ù„Ø¢ÙŠØ©:", height=150)

        if st.button("ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙØ³ÙŠØ±"):
            if user_tafsir.strip() == "":
                st.warning("Ù…Ù† ÙØ¶Ù„Ùƒ Ø§ÙƒØªØ¨ ØªÙØ³ÙŠØ±Ù‹Ø§")
            else:
                correct, feedback = tafsir_agent.check_tafsir(current_ayah_num, user_tafsir)
                st.markdown(f"**Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªÙØ³ÙŠØ±:** {feedback}")

                if llm_helper:
                    prompt = f"Ù‚Ø§Ø±Ù† ØªÙØ³ÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ø¹ Ø§Ù„ØªÙØ³ÙŠØ± Ø§Ù„ØµØ­ÙŠØ­ ÙˆÙ‚Ù„ Ù„ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù† ØµØ­ÙŠØ­ Ø£Ùˆ ÙŠØ­ØªØ§Ø¬ ØªØµØ­ÙŠØ­:\n{user_tafsir}"
                    llm_feedback = llm_helper.ask(prompt)
                    st.markdown(f"**Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:** {llm_feedback}")

        # Ø²Ø± Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù„Ù„Ø¢ÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ©
        if st.button("Ø§Ù„Ø¢ÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ©"):
            if not data_agent.next_ayah():
                st.success("Ø§Ù†ØªÙ‡Øª Ø§Ù„Ø¢ÙŠØ§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©")
            else:
                # Ø¥Ø¹Ø§Ø¯Ø© Ø¶Ø¨Ø· Ø§Ù„Ù†ØµÙˆØµ
                st.session_state.user_memorization = ""
                st.session_state.user_tafsir = ""
                st.experimental_rerun()

        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        if "results" not in st.session_state:
            st.session_state.results = []

        # Ø­ÙØ¸ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø¨Ø¹Ø¯ ÙƒÙ„ ØªØ­Ù‚Ù‚ (ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙˆÙ‚ÙŠØª)
        if st.button("Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©"):
            st.session_state.results.append({
                "ayah_number": current_ayah_num,
                "user_memorization": user_memorization,
                "memorization_feedback": feedback if 'feedback' in locals() else "",
                "user_tafsir": user_tafsir,
                "tafsir_feedback": feedback if 'feedback' in locals() else ""
            })
            st.success("ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©")

        # ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
        if st.session_state.results:
            csv_buffer = StringIO()
            writer = csv.DictWriter(csv_buffer, fieldnames=["ayah_number", "user_memorization", "memorization_feedback", "user_tafsir", "tafsir_feedback"])
            writer.writeheader()
            writer.writerows(st.session_state.results)
            st.download_button(
                label="ØªØ­Ù…ÙŠÙ„ Ù†ØªØ§Ø¦Ø¬Ùƒ ÙƒÙ…Ù„Ù CSV",
                data=csv_buffer.getvalue(),
                file_name="quran_memorization_results.csv",
                mime="text/csv"
            )


if __name__ == "__main__":
    app()
