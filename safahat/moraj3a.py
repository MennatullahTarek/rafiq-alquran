import streamlit as st
import requests
from PIL import Image, ImageDraw, ImageFont
from io import StringIO
import csv
from huggingface_hub import InferenceClient


import os
HF_TOKEN = os.getenv("HF_TOKEN")  

HF_MODEL = "gpt2"  


client = InferenceClient(model=HF_MODEL, token=HF_TOKEN)



surahs = {
    "Ø§Ù„ÙØ§ØªØ­Ø©": 1,
    "Ø§Ù„Ø¨Ù‚Ø±Ø©": 2,
    "Ø¢Ù„ Ø¹Ù…Ø±Ø§Ù†": 3,
    "Ø§Ù„Ù†Ø³Ø§Ø¡": 4,
    "Ø§Ù„Ù…Ø§Ø¦Ø¯Ø©": 5,
    "Ø§Ù„Ø£Ù†Ø¹Ø§Ù…": 6,
    "Ø§Ù„Ø£Ø¹Ø±Ø§Ù": 7,
    "Ø§Ù„Ø£Ù†ÙØ§Ù„": 8,
    "Ø§Ù„ØªÙˆØ¨Ø©": 9,
    "ÙŠÙˆÙ†Ø³": 10,
    "Ù‡ÙˆØ¯": 11,
    "ÙŠÙˆØ³Ù": 12,
    "Ø§Ù„Ø±Ø¹Ø¯": 13,
    "Ø¥Ø¨Ø±Ø§Ù‡ÙŠÙ…": 14,
    "Ø§Ù„Ø­Ø¬Ø±": 15,
    "Ø§Ù„Ù†Ø­Ù„": 16,
    "Ø§Ù„Ø¥Ø³Ø±Ø§Ø¡": 17,
    "Ø§Ù„ÙƒÙ‡Ù": 18,
    "Ù…Ø±ÙŠÙ…": 19,
    "Ø·Ù‡": 20,
    "Ø§Ù„Ø£Ù†Ø¨ÙŠØ§Ø¡": 21,
    "Ø§Ù„Ø­Ø¬": 22,
    "Ø§Ù„Ù…Ø¤Ù…Ù†ÙˆÙ†": 23,
    "Ø§Ù„Ù†ÙˆØ±": 24,
    "Ø§Ù„ÙØ±Ù‚Ø§Ù†": 25,
    "Ø§Ù„Ø´Ø¹Ø±Ø§Ø¡": 26,
    "Ø§Ù„Ù†Ù…Ù„": 27,
    "Ø§Ù„Ù‚ØµØµ": 28,
    "Ø§Ù„Ø¹Ù†ÙƒØ¨ÙˆØª": 29,
    "Ø§Ù„Ø±ÙˆÙ…": 30,
    "Ù„Ù‚Ù…Ø§Ù†": 31,
    "Ø§Ù„Ø³Ø¬Ø¯Ø©": 32,
    "Ø§Ù„Ø£Ø­Ø²Ø§Ø¨": 33,
    "Ø³Ø¨Ø£": 34,
    "ÙØ§Ø·Ø±": 35,
    "ÙŠØ³": 36,
    "Ø§Ù„ØµØ§ÙØ§Øª": 37,
    "Øµ": 38,
    "Ø§Ù„Ø²Ù…Ø±": 39,
    "ØºØ§ÙØ±": 40,
    "ÙØµÙ„Øª": 41,
    "Ø§Ù„Ø´ÙˆØ±Ù‰": 42,
    "Ø§Ù„Ø²Ø®Ø±Ù": 43,
    "Ø§Ù„Ø¯Ø®Ø§Ù†": 44,
    "Ø§Ù„Ø¬Ø§Ø«ÙŠØ©": 45,
    "Ø§Ù„Ø£Ø­Ù‚Ø§Ù": 46,
    "Ù…Ø­Ù…Ø¯": 47,
    "Ø§Ù„ÙØªØ­": 48,
    "Ø§Ù„Ø­Ø¬Ø±Ø§Øª": 49,
    "Ù‚": 50,
    "Ø§Ù„Ø°Ø§Ø±ÙŠØ§Øª": 51,
    "Ø§Ù„Ø·ÙˆØ±": 52,
    "Ø§Ù„Ù†Ø¬Ù…": 53,
    "Ø§Ù„Ù‚Ù…Ø±": 54,
    "Ø§Ù„Ø±Ø­Ù…Ù†": 55,
    "Ø§Ù„ÙˆØ§Ù‚Ø¹Ø©": 56,
    "Ø§Ù„Ø­Ø¯ÙŠØ¯": 57,
    "Ø§Ù„Ù…Ø¬Ø§Ø¯Ù„Ø©": 58,
    "Ø§Ù„Ø­Ø´Ø±": 59,
    "Ø§Ù„Ù…Ù…ØªØ­Ù†Ø©": 60,
    "Ø§Ù„ØµÙ": 61,
    "Ø§Ù„Ø¬Ù…Ø¹Ø©": 62,
    "Ø§Ù„Ù…Ù†Ø§ÙÙ‚ÙˆÙ†": 63,
    "Ø§Ù„ØªØºØ§Ø¨Ù†": 64,
    "Ø§Ù„Ø·Ù„Ø§Ù‚": 65,
    "Ø§Ù„ØªØ­Ø±ÙŠÙ…": 66,
    "Ø§Ù„Ù…Ù„Ùƒ": 67,
    "Ø§Ù„Ù‚Ù„Ù…": 68,
    "Ø§Ù„Ø­Ø§Ù‚Ø©": 69,
    "Ø§Ù„Ù…Ø¹Ø§Ø±Ø¬": 70,
    "Ù†ÙˆØ­": 71,
    "Ø§Ù„Ø¬Ù†": 72,
    "Ø§Ù„Ù…Ø²Ù‘Ù…Ù‘Ù„": 73,
    "Ø§Ù„Ù…Ø¯Ù‘Ø«Ø±": 74,
    "Ø§Ù„Ù‚ÙŠØ§Ù…Ø©": 75,
    "Ø§Ù„Ø¥Ù†Ø³Ø§Ù†": 76,
    "Ø§Ù„Ù…Ø±Ø³Ù„Ø§Øª": 77,
    "Ø§Ù„Ù†Ø¨Ø£": 78,
    "Ø§Ù„Ù†Ø§Ø²Ø¹Ø§Øª": 79,
    "Ø¹Ø¨Ø³": 80,
    "Ø§Ù„ØªÙƒÙˆÙŠØ±": 81,
    "Ø§Ù„Ø¥Ù†ÙØ·Ø§Ø±": 82,
    "Ø§Ù„Ù…Ø·ÙÙ‘ÙÙŠÙ†": 83,
    "Ø§Ù„Ø¥Ù†Ø´Ù‚Ø§Ù‚": 84,
    "Ø§Ù„Ø¨Ø±ÙˆØ¬": 85,
    "Ø§Ù„Ø·Ø§Ø±Ù‚": 86,
    "Ø§Ù„Ø£Ø¹Ù„Ù‰": 87,
    "Ø§Ù„ØºØ§Ø´ÙŠØ©": 88,
    "Ø§Ù„ÙØ¬Ø±": 89,
    "Ø§Ù„Ø¨Ù„Ø¯": 90,
    "Ø§Ù„Ø´Ù…Ø³": 91,
    "Ø§Ù„Ù„ÙŠÙ„": 92,
    "Ø§Ù„Ø¶Ø­Ù‰": 93,
    "Ø§Ù„Ø´Ø±Ø­": 94,
    "Ø§Ù„ØªÙŠÙ†": 95,
    "Ø§Ù„Ø¹Ù„Ù‚": 96,
    "Ø§Ù„Ù‚Ø¯Ø±": 97,
    "Ø§Ù„Ø¨ÙŠÙ†Ø©": 98,
    "Ø§Ù„Ø²Ù„Ø²Ù„Ø©": 99,
    "Ø§Ù„Ø¹Ø§Ø¯ÙŠØ§Øª": 100,
    "Ø§Ù„Ù‚Ø§Ø±Ø¹Ø©": 101,
    "Ø§Ù„ØªÙƒØ§Ø«Ø±": 102,
    "Ø§Ù„Ø¹ØµØ±": 103,
    "Ø§Ù„Ù‡Ù…Ø²Ø©": 104,
    "Ø§Ù„ÙÙŠÙ„": 105,
    "Ù‚Ø±ÙŠØ´": 106,
    "Ø§Ù„Ù…Ø§Ø¹ÙˆÙ†": 107,
    "Ø§Ù„ÙƒÙˆØ«Ø±": 108,
    "Ø§Ù„ÙƒØ§ÙØ±ÙˆÙ†": 109,
    "Ø§Ù„Ù†ØµØ±": 110,
    "Ø§Ù„Ù…Ø³Ø¯": 111,
    "Ø§Ù„Ø¥Ø®Ù„Ø§Øµ": 112,
    "Ø§Ù„ÙÙ„Ù‚": 113,
    "Ø§Ù„Ù†Ø§Ø³": 114
}


def get_ayah_text(surah_num, ayah_num):
    url = f"https://api.quran.com/api/v4/quran/verses/uthmani?verse_key={surah_num}:{ayah_num}"
    response = requests.get(url)
    if response.status_code == 200:
        try:
            return response.json()['verses'][0]['text_uthmani']
        except Exception:
            return "âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Øµ Ø§Ù„Ø¢ÙŠØ©."
    else:
        return "âŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¬Ù„Ø¨ Ù†Øµ Ø§Ù„Ø¢ÙŠØ©."

def get_tafsir(surah_num, ayah_num, tafsir_id=91):
    url = f"https://api.quran.com/api/v4/tafsirs/{tafsir_id}/by_ayah/{surah_num}:{ayah_num}"
    response = requests.get(url)
    if response.status_code == 200:
        try:
            return response.json()['tafsir']['text']
        except Exception:
            return "âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ³ÙŠØ±."
    else:
        return "âŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¬Ù„Ø¨ Ø§Ù„ØªÙØ³ÙŠØ±."

# 6- Ø¯Ø§Ù„Ø© Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ ÙˆØ§Ù„ØµÙˆØ±Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ - Ù…Ù…ÙƒÙ† ØªØ³ØªØ®Ø¯Ù… Ù„Ù„Ø¹Ø±Ø¶ Ø¨ØµÙŠØºØ© ØµÙˆØ±Ø©)
def text_to_image(text, tafsir, font_path="arial.ttf", font_size=28, tafsir_font_size=18):
    width, height = 800, 600
    img = Image.new("RGB", (width, height), color="white")
    draw = ImageDraw.Draw(img)

    try:
        font = ImageFont.truetype(font_path, font_size)
        tafsir_font = ImageFont.truetype(font_path, tafsir_font_size)
    except IOError:
        font = ImageFont.load_default()
        tafsir_font = ImageFont.load_default()

    draw.text((width - 50, 50), text, fill="black", font=font, anchor="ra", direction="rtl")

    lines = []
    words = tafsir.split()
    line = ""
    for word in words:
        test_line = (line + " " + word).strip()
        if draw.textlength(test_line, font=tafsir_font) < width - 100:
            line = test_line
        else:
            lines.append(line)
            line = word
    lines.append(line)

    y_text = 150
    for line in lines:
        draw.text((50, y_text), line.strip(), fill="black", font=tafsir_font)
        y_text += tafsir_font_size + 8  

    return img


class HuggingFaceLLM:
    def __init__(self, model_name=HF_MODEL, token=HF_TOKEN):
        self.model_name = model_name
        self.token = token
        self.client = InferenceClient(model=self.model_name, token=self.token)

    def generate_text(self, prompt, max_tokens=200):
        # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API
        response = self.client.text_generation(
            inputs=prompt,
            max_new_tokens=max_tokens,
            do_sample=True,
            temperature=0.7,
        )
        # response Ù‡ÙŠ dict Ø¨Ù‡Ø§ 'generated_text'
        return response.generated_text if hasattr(response, 'generated_text') else response[0]['generated_text']


class MemorizationAgent:
    def __init__(self, llm: HuggingFaceLLM):
        self.llm = llm
        self.memory = []

    def memorize(self, text):
        self.memory.append(text)
        return f"ØªÙ… Ø­ÙØ¸: {text}"

class InferenceAgent:
    def __init__(self, llm: HuggingFaceLLM):
        self.llm = llm

    def infer(self, prompt):
        return self.llm.generate_text(prompt)

class InteractionAgent:
    def __init__(self, llm: HuggingFaceLLM):
        self.llm = llm

    def interact(self, prompt):
        return self.llm.generate_text(prompt)


llm = HuggingFaceLLM()
memorization_agent = MemorizationAgent(llm)
inference_agent = InferenceAgent(llm)
interaction_agent = InteractionAgent(llm)


def app():
    st.title("ğŸ“– ØªÙØ³ÙŠØ± Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ… Ù…Ø¹ Ø¯Ø¹Ù… LLM")


    surah_name = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø³ÙˆØ±Ø©", list(surahs.keys()))

  
    ayah_num = st.number_input("Ø±Ù‚Ù… Ø§Ù„Ø¢ÙŠØ©", min_value=1, value=1)

    if "memory" not in st.session_state:
        st.session_state.memory = []

    if st.button("ğŸ“š Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ³ÙŠØ± ÙˆØ§Ù„Ù†Øµ"):
        surah_num = surahs[surah_name]
        ayah_text = get_ayah_text(surah_num, ayah_num)
        tafsir = get_tafsir(surah_num, ayah_num)

        st.subheader("ğŸ“– Ù†Øµ Ø§Ù„Ø¢ÙŠØ©:")
        st.markdown(f"<div style='font-size:28px; direction: rtl; text-align: right;'>{ayah_text}</div>", unsafe_allow_html=True)

        st.subheader("ğŸ“— Ø§Ù„ØªÙØ³ÙŠØ±:")
        st.markdown(tafsir, unsafe_allow_html=True)

        # Ø­ÙØ¸ Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙÙŠ session state (Ù…Ø«Ù„Ø§Ù‹ ØªÙ‚Ø¯Ø± ØªØ³ØªØ®Ø¯Ù… Ù„Ø­ÙØ¸ Ø§Ù„Ø­ÙˆØ§Ø±Ø§Øª Ø£Ùˆ Ø§Ù„ØªÙØ³ÙŠØ±Ø§Øª)
        st.session_state.memory.append({"surah": surah_name, "ayah": ayah_num, "text": ayah_text, "tafsir": tafsir})

        # Ø¹Ø±Ø¶ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        st.write("ğŸ§  Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªÙØ³ÙŠØ± (Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…):")
        for i, mem in enumerate(st.session_state.memory):
            st.write(f"{i+1}. Ø³ÙˆØ±Ø© {mem['surah']} Ø¢ÙŠØ© {mem['ayah']}: {mem['text']}")

        # ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù CSV
        csv_buffer = StringIO()
        csv_writer = csv.writer(csv_buffer)
        csv_writer.writerow(["Ø§Ù„Ø³ÙˆØ±Ø©", "Ø±Ù‚Ù… Ø§Ù„Ø¢ÙŠØ©", "Ù†Øµ Ø§Ù„Ø¢ÙŠØ©", "Ø§Ù„ØªÙØ³ÙŠØ±"])
        for mem in st.session_state.memory:
            csv_writer.writerow([mem['surah'], mem['ayah'], mem['text'], mem['tafsir']])

        st.download_button(
            label="ğŸ’¾ ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ Ø§Ù„ØªÙØ³ÙŠØ±Ø§Øª ÙƒÙ…Ù„Ù CSV",
            data=csv_buffer.getvalue(),
            file_name=f"tafsir_all.csv",
            mime="text/csv"
        )

    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù€ agents
    st.markdown("---")
    st.subheader("ğŸ§  Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© - Ø­ÙØ¸ Ù†Øµ")
    text_to_memorize = st.text_input("Ø§ÙƒØªØ¨ Ù†Øµ Ù„Ù„Ø­ÙØ¸:")
    if st.button("Ø­ÙØ¸ Ø§Ù„Ù†Øµ"):
        result = memorization_agent.memorize(text_to_memorize)
        st.success(result)

    st.subheader("ğŸ¤– Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ù† Ø®Ù„Ø§Ù„ LLM")
    prompt = st.text_area("Ø§Ø¯Ø®Ù„ Ù†Øµ Ù„Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬:")
    if st.button("Ø§Ø³ØªÙ†ØªØ¬"):
        answer = inference_agent.infer(prompt)
        st.markdown(f"**Ø§Ù„Ù†ØªÙŠØ¬Ø©:** {answer}")

    st.subheader("ğŸ’¬ Ø§Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ LLM")
    interaction_prompt = st.text_area("Ø§Ø¯Ø®Ù„ Ù†Øµ Ù„Ù„ØªÙØ§Ø¹Ù„:")
    if st.button("ØªÙØ§Ø¹Ù„"):
        response = interaction_agent.interact(interaction_prompt)
        st.markdown(f"**Ø§Ù„Ø±Ø¯:** {response}")



if __name__ == "__main__":
    app()
